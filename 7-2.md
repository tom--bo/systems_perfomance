[https://www.amazon.co.jp/Systems-Performance-Enterprise-Brendan-Gregg/dp/0133390098:title=Systems Performance: Enterprise and Cloud]を読んでいく。

[http://tombo2.hatenablog.com/entry/2016/12/15/224237:title=前回]の続き。  
7章3節メモリアーキテクチャを2つに分けて、前半のハードウェア部分。

## 7.3 Architecture

この章ではプロセッサとOSを含むハードとソフト両方のメモリアーキテクチャについて紹介する。

### 7.3.1 Hardware

メモリのハードウェアは、メインメモリ、バス、CPUキャッシュ、MMU等がある。

[Main Memory]

最近一般的にメインメモリとして使われているのはDRAM(dynamic random-access memory)である。

[Latency]

メインメモリのレイテンシーは"column address strobe(CAS)"レイテンシとして計測され、これは目的とするアドレス（カラム）にメモリモジュールを送ってから読み出しが可能になるまでの時間である。
これはメモリのタイプによって異なり、DDR3では約10nsである。
I/Oの転送の度に、メモリバスがキャッシュラインを変換するためにこのレイテンシーが複数回発生する。
他にも新しく利用可能になったデータのためのCPUやMMUを含むレイテンシもある。

[Main Memory Architecture]

メインメモリの例として図7.3に一般的な2プロセッサの"uniform memory access(UMA)"システムを示す。
それぞれのCPUは全てのメモリに対して、共通のシステムバスを通じて、統一されたアクセスレイテンシを持っている。

図7.3?

システムが1つのカーネルで運用されているとき、これらは全てのプロセッサで統一して動いている。
また、これはsymmetric multiprocessing(SMP)アーキテクチャでも同様である。

比較として、2プロセッサの"non-uniform memory access(NUMA)"システムの例を図7.4に示す。
これはメモリアーキテクチャの一部となったCPUインターコネクトを使っている。
この仕組に酔って、メインメモリへのアクセス時間はCPUとの位置関係に酔って変化するようになった。

図7.4?

CPU1はDRAM Aとメモリバスを介して直接I/Oを行うことが出来、これを"local memory"と呼ぶ。一方で、CPU1はDRAM Bとは、CPU1とCPUインターコネクト(2ホップ)を介してI/Oを行い、これを"remote memory"と呼ぶ。

[Busses]

個々までで示したように、どれだけ物理的にメインメモリがシステムにつながっていて、実際の実装ではさらなるコントローラやバスが含まれており、以下のうちのいずれかの方法でアクセスされている。

- shared system Busses
  - シングル/マルチプロセッサにおいて、メモリとコントローラ、最後にはメモリバスをブリッジする共有システムバスを介す。
  - これはUMAの例として、図7.3で示したものであり、Intel front-sideバスとして図6.9で示したものでもある。その例のメモリコントローラはNorthbridgeである。
- Direct
  - メモリバスを介して直接紐付けられているメモリを介すシングルプロセッサの仕組み
- Interconnect
  - マルチプロセッサ環境で、それぞれのプロセッサではメモリバスを介して直接接続し、プロセッサ同士はインターコネクトでつなぐ。
  - これは図7.4で示した者で、6章で議論したものである。

[DDR SDRAM]
